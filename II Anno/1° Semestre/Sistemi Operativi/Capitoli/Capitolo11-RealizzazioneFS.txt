CAPITOLO 11:  REALIZZAZIONE DEL  FILE SYSTEM 
 
Il file system fornisce il meccanismo per la memorizzazione e l’accesso al contenuto dei file, compresi dati e programmi. Il file system risiede permanentemente nella memoria secondaria, progettata per ottenere in modo permanente grandi quantità di dati 

1. STRUTTURA DEL FILE SYSTEM 
I dischi costituiscono la maggior parte della memoria secondaria in cui si conserva il file system hanno due caratteristiche importanti: si possono scrivere localmente e si può accedere direttamente a qualsiasi blocco. Anziché trasferire un byte alla volta, per migliorare l’efficienza dell’IO vengono trasferiti interi blocchi. Per fornirne un efficiente e conveniente accesso ad disco, il So fa uno di uno o più file system. Un file system presenta due problemi di progettazione piuttosto diversi. Il primo riguarda la definizione dell’aspetto dei file system agli occhi utente. Un file system di solito è composto da molti livelli distinti.  
 
Il livello più basso è il controllo dell’I/O costituito dai driver dei dispositivi e dai gestori di segnali. Un driver di dispositivi può concepire come un traduttore di comandi. Il file system di base deve soltanto inviare dei generici comandi appropriato driver di dispositivo per leggere e scrivere blocchi fisici nel disco. Ogni blocco si identifica col suo indirizzo numerico nel disco. Il modulo di organizzazione dei file è a conoscenza dei file e dei loro blocchi logici e cosi come dei blocchi fisici dei dischi. Conoscendo il tipo di allocazione dei file usato e la locazione dei file, può tradurre gli indirizzi dei blocchi negli indirizzi dei blocchi fisici. Infine il file system logico gestisce i metadati; si tratta di tute le strutture del file system eccetto gli effettivi dati.  Nei file system stratificati la duplicazione di codice è ridotta al minimo. Il controllo dell’I/O e talvolta il codice di base del file system possono essere comuni a numerosi file system che pi gestiscono il file system logico e i moduli per l’organizzazione dei file. 

2. REALIZZAZIONE DEL FILE SYSTEM 
Per realizzare un file system si usano parecchie strutture dati, sia nei dischi sia in memoria. Queste strutture variano secondo il SO e il file system. Nei dischi il file system teine informazioni su come eseguire l’avviamento di un SO memorizzato nei dischi stessi, il numero totale di blocchi, il numero e la locazione dei blocchi liberi. Molte di loro sono analizzate in modo particolare. Fra le strutture dati troviamo: 
? il blocco di controllo dell’avviamento. Il boot control block contiene le informazioni al sistema per l’avviamento di un SO da quel volume. Se un disco non contiene un So quel blocco è vuoto.  
? Blocchi di controllo dei volumi. Ciascuno di loro contiene i dettagli relativo al volume come il numero e la dimensione dei blocchi 
? Le strutture delle directory. Usate per organizzare i file. Nel caso di unix in nomi dei file e i numeri sono memorizzati nell’i-node in win ossia con il file system NTFS nella tabella principale dei file (master file table) 
? I blocchi di controllo dei file. FCB Contenenti molti dettagli dei file compresi i permessi 

Le informazioni tenute in memoria servono sia per la gestione del file system sia per migliorare le prestazione attraverso l’uso d cache. Id dati si caricano al momento del montaggio e si eliminano allo smontaggio. Le strutture contenenti queste informazioni comprendono: la tabella di montaggio interna alla memoria che contiene informazioni relative a ciascun volume montato; la struttura delle directory tenute in memoria contenente le informazioni relative a tute le dir a cui i processi hanno avuto accesso di recente; la tabella generale dei file aperti; la tabella dei file aperti per ciascuno processo. 
Le applicazioni per creare un nuovo file, eseguono una chiamata al file system logico, il quale conosce il formato della struttura della dir. Il sistema carica quindi la dir. Esso crea e alloca un nuovo FCB. Alcuni SO, compreso unix, trattano le dir esattamente come i file, distinguendoli con un campo per il tipo, mentre il SO win NT dispone di chiamate di sistema appropriato per le dir.  Una volta che il file è stato trovato, si copia l’FCB nella tabella generale di file aperti. Questa tabella non contiene solo l’FCB ma tiene conto anche del numero di processi che utilizza il file. Il nome dato all’elemento della tabella è detto FD per unix e file handle per win.   

|||||PARTIZIONI E MONTAGGIO 
Un disco si può configurare in vari modi, secondo il SO che lo gestisce. Si può suddivider in più partizioni, oppure un volume può comprendere più partizioni su molteplici dischi.  Ciascuna partizione è priva di struttura logica se non contiene alcun file system ed è detto raw disk. Alcuni SO quali UNIX impiega una partizione priva di struttura per l’area di avvicendamento. Un disco privo di stortura logica può anche contenere informazioni necessarie per sistemi RAID di gestione dei dischi. Le informazioni relative all’avviamento del sistema si possono registrare in un’apposita partizione, che anche il questo caso ha un proprio formato perché nella fase di avviamento il sistema non ha ancora caricato i driver di dispositivo del file system quindi non può interpretano il formato. Nei pc si può configurare una installazione di più SO e durante la fase di boot l’utente sceglie quale SO avviare. Nella fase di caricamento il SO esegue il montaggio della partizione radice che contiene il kernel dei sistema operativo e in alcuni casi altri file di sistema. Secondo il sistema operativo, il montaggio degli altri volumi avviene automaticamente in questa fase oppure si può compiere successivamente in modo esplicito. Durante l’operazione di montaggio, il sistema verifica la coerenza della partizione e una eventuale correzione. Infine annota nella struttura della tabella di montaggio che un file system è stato montato.

3. REALIZZAZIONE DELLE DIRECTORY 
La selezione degli algoritmi di allocazione e degli algoritmi di gestione delle dir ha un grande effetto sull'efficienza, le prestazioni e l'affidabilità del file system.   

|||||LISTA LINEARE
Il più semplice metodo di realizzazione di una dir è basato sull’uso si una lista lineare contenente i nomi dei file con puntatori ai blocchi di dati. Questo metodo è di facile programmazione, ma la sua esecuzione è onerosa in termini di tempo. Per creare un nuovo file occorre prima esaminare la directory per essere sicuri che non esista gia un file con Io stesso nome, quindi aggiungere un nuovo elemento alla fine della dir. Per cancellare un file occorre cercare nella dir il file con quel nome, quindi rilasciare lo spazio che gli era assegnano.  
Esistono vari metodi  per riutilizzare un elemento della directory: si può contrassegnare l’elemento come un usato oppure può essere aggiunto a una lista di elementi di dir liberi una terza  possibilità prevede la copiatura dell'ultimo elemento della dir in una locazione liberata e a diminuzione della lunghezza,della directory. Il vero svantaggio dato da una lista lineare di elementi di directory è dato dalla ricerca lineare di un file. Le informazioni sulla diretto vengono usate frequentemente, e gli utenti avvertirebbero una gestione lenta e accesso a tali informazioni. In effetti, molti SO impiegano una cache per memorizzare le informazioni sulla dir usata più recentemente. Una lista ordinata permette una ricerca binaria e riduce il tempo medio di ricerca. Un vantaggio della lista ordinata è che consente di produrre l'elemento, ordinato del contenuto della directory senza una fase d'ordinamento separata. 

|||||TABELLA HASH
Un'altra struttura dati che si usa per realizzare le directory è la tabella hash. In questo metodo una lista lineare contiene gli elementi di directory, ma si usa anche una struttura dati hash. La tabella hash riceve un valore calcolato usando come operando il nome del file e riportai puntatore al nome del file nella lista lineare. Attraverso questa struttura dati si può diminuire nettamente del tempo di ricerca nella dir. L’inserimento e la cancellazione sono abbastanza semplici anche se occorre prender provvedimenti per evitare collisioni. Per eliminare la collisione invece che un singolo valore, può essere concatenata a ciascun elemento una lista.  

4. METODI DI ALLOCAZIONE 
La natura ad accesso diretto dei dischi permette una certa flessibilità nella realizzazione dei file. Molti file si memorizzano nello stesso disco. Il problema principale consiste dunque nell’allocare lo spazio per questi file in modo che lo spazio nel disco sia usato efficientemente e l’accesso ai file sia rapido. Esistono 3 metodi principali per l’allocazione della spazio di un disco: può essere contigua, concatenata o indicizzata. 
 
|||||ALLOCAZIONE CONTIGUA
Per usare il metodi di allocazione contigua ogni file deve occupare un insieme di blocchi contigui del disco. Gli indirizzi del disco definiscono un ordinamento lineare nel disco stesso. Con questo ordinamento l’accesso al blocco b+1 dopo il blocco b non richiede normalmente alcuno spostamento della testina. Quindi il numero dei posizionamenti richiesti per accedere a file il cui spazio è allocato il modo contiguo è trascurabile, cosi come è trascurabile il tempo di ricerca. 
Accedere ad un file in cui la sua allocazione è contigua, è facile. Quando si usa un accesso sequenziale, il file system memorizza l’indirizzo dell’ultimo blocco a cui è stato fatto riferimenti e se è necessario legge il blocco successivo. L’allocazione contigua presenta pero alcuni problemi una difficoltà riguarda l’individuazione dello spazio per un nuovo file. La realizzazione del sistema di gestione dello spazio libero determina il modo in cui tale compito viene eseguito. Si può usare ogni sistema di gestione anche se alcuni sono più lenti di altri Per l’allocazione contigua si possono usare gli stessi criteri dell’allocazione dinamica della memoria: il problema generale infatti è quello di soddisfare una richiesta di dimensione n data una lista di buchi liberi. I più comuni criteri di ricerca del buco libero sono first fit e best fit. Questi algoritmi soffrono della frammentazione esterna. Una soluzione detta deframmentazione è quella di copiare i file system in un altro supporto e successivamente riscriverlo in modo compatto ma questo sprecava molto temo. Alcuni sistemi dovevano effettuarlo offline, i nuovi lo fanno ondine. Un altro problema è da determinazione della quantità di spazio necessaria. Un file può avere poco spazio e quindi si possono avere 2 soluzioni: o nel momento della creazione si da molto spazio oppure nel momento che questo cresce si copia in un buco libero più grande e quello precedente si libera. Per ridurre al minimo questo problema alcuni SO fanno uso di una versione modificata: inizialmente si assegna una porzione di spazio contiguo e se questa non p abbastanza grande si aggiunge un’altra porzione di spazio. 

|||||ALLOCAZIONE CONCATENATA
L’allocazione concatenata risolve tutti i problemi sorti dall’allocazione contigua. Con questo tipo di allocazione ogni file è composto da una lista concatenata di blocchi del disco i quali possono essere sparsi ovunque. Per creare un nuovo file si crea semplicemente un nuovo elemento della dir. Un’operazione di scrittura determina la ricerca di un blocco libero, la scrittura di tale blocco e la concatenazione di tale blocco. Per leggere un file basta semplicemente scorrere tutto il file. Non è necessario dichiarare a priori la grandezza del file. Gli svantaggi di questo tipo di allocazione è che può essere usata efficientemente solo per i file ad accesso sequenziale in quanto quelli diretti non è possibile in modo veloce sapere il blocco i. un altro svantaggio è lo spazio richiesto per i puntatori. Per risolvere questo problema è possibile riunire un numero di blocchi detti cluster ed effettuare il puntamento solo di cluster a cluster. Questo metodo migliora la produttività del disco. Un altro problema riguarda l’affidabilità. Poiché sono tenuti molti puntatori, se per errore uno di questi venisse cancellato, non si potrebbe accedere a tutto il file. Una variante importante del metodo di allocazione concatenata consiste nell’uso della tabella di allocazione dei file FAT. Per contenere tale tabella si riserva una sezione del disco all’inizio di ciascun volume. La FAT ha un elemento per ogni blocco del disco ed è indicizzata dal numero di blocco, si usa essenzialmente come una lista concatenata. Lo schema di allocazione basato sulla FAT se non si usa una cache può causare un significativo numero di posizionamenti della testina. La testina deve spostarsi all’inizio per leggere la FAT e poi leggere il blocco. 

|||||ALLOCAZIONE INDICIZZATA
L’allocazione concatenata risolve il problema della frammentazione esterna e quello della dichiarazione della dimensione dei file. Tuttavia in mancanza di una FAT l’allocazione concatenata non è in grado di sostenere un efficiente accesso diretto. L’allocazione indicizzata risolve questo problema raggruppando tutti i puntatori in una sola locazione. Ogni file ha il proprio blocco indice: si tratta di un array d’indirizzi di blocchi del disco.  Una volta creato il file, tutti i puntatori del blocco indice sono impostati a nil. Non appena si scrive il blocco i si aggiorna il puntatore i. l’allocazione indicizzata consente l’accesso diretto senza soffrire di frammentazione esterna.  
Ogni file deve avere un blocco indice. Ci sono diversi schemi di realizzazione dei blocchi indici: 
? Schema concatenato. Un blocco indice è formato normalmente di uno solo blocco di disco perciò ciascun blocco indice può essere letto e scritto esattamente con un’operazione. Per permettere la presenza di lunghi file è possibile collegare tra loro parecchi blocchi indice.  
? Indice a più livelli. Una variante della rappresentazione concatenata consiste nell’impiego di un blocco indice di primo livello che punta a un insieme di blocchi indice di secondo livello che  loro volta puntano ai blocchi dei file. 
? Schema combinato. Un’altra possibilità è la soluzione adottata da UNIX che consiste nell’avere i primi 15 puntatori del indice dell’inode. I primi 12 puntano a blocchi su disco, gli altri 3 puntano a blocchi indiretti che sono rispettivamente singolo, doppio e triplo.      

|||||PRESTAZIONI
I metodi d’allocazione presentati hanno diversi livelli di efficienza di memorizzazione e differenti tempi d’accesso ai blocchi di dati. Prima di sceglier un metodo di allocazione è necessario determinare il modo in cui si usano i sistemi: un sistema con una prevalenza di accessi sequenziali farà uso in un metodo differente da quello con prevalenza di accessi diretti.  Per qualsiasi tipo di accesso, l’allocazione contigua richiede un solo accesso per ottener un blocco. Poiché è facile tenere l’indirizzo iniziale de file in memoria, si può calcolare immediatamente l’indirizzo del disco dell’i-esimo blocco. Con l’allocazione concatenata si può tenere in memoria anche l’indirizzo del blocco successivo e leggerlo direttamente. Questo metodo è valido per l’accesso sequenziale mentre per quel che riguarda l’accesso diretto un accesso  all’i-simo blocco può richiedere i letture del disco. Da tutto ciò segue che alcuni sistemi gestiscono i file ad accesso diretto usando l’allocazione contigua e i file ad accesso sequenziale tramite l’allocazione concatenata. L’allocazione indicizzata è più complessa. Se il blocco indice è gia in memoria l’accesso può essere diretto. Tuttavia per tenere il blocco indice in memoria occorre una quantità di spazio notevole. Le prestazioni di tale allocazione dipenono dalla struttura dell’indice, dalla dimensione del file e dalla posizione del blocco. Alcuni SO combinano le allocazioni in base alle proprie esigenze.  

5. GESTIONE DELLO SPAZIO LIBERO 
Poiché la quantità di spazio dei dischi è limitata, è necessario utilizzare lo spazio lasciato dai file cancellati per scrivere nuovi file. Per tener traccia dello spazio libero in un disco, il sistema conserva una lista dello spazio libero. Per creare file occorre cercare nella lista dello spazio la quantità di spazio necessaria e assegnarla al nuovo file  

|||||VETTORE DI BIT
Spesso la lista dello spazio libero si realizza come una mappa di bit o vettore di bit. ogni blocco è rappresentato da un bit: se il blocco è libero il bit è 1, altrimenti e 0. i vantaggi principali che derivano da questo metodo sono la sua relativa semplice ed efficienza nel trovare il primo blocco libero e n blocchi liberi consecutivi nel disco.  Sfortunatamente i vettori di bit sono efficienti solo se tutto il vettore è mantenuto in memoria centrale e viene di tanto in tanto scritto in memoria secondaria allo scopo di consentire eventuali operazioni di ripristino.   

|||||LISTA CONCATENATA 
Un altro metodo di gestione degli spazi liberi consiste nel collegarli tutti, tenere un puntatore al primo di questi in una speciale locazione del disco e caricalo in memoria. Questo primo blocco contiene un puntatore al successivo blocco libero e cosi via. Questo schema non è tuttavia efficiente: per attraversare la lista occorre leggere ogni blocco e l’operazione richiede un notevole tempo di IO. Fortunatamente l’attraversamento della lista dello spazio libero non è un’operazione frequente. Il metodo oche fa uso della fat include il conteggio dei blocchi liberi nella struttura dati per l’allocazione.  
 
|||||RAGGRUPPAMENTO
Una possibile modifica del metodo della lista dello spazio libero prevede la memorizzazione degli indirizzi in n blocchi liberi nel primo di questi. I primi n-1 sono effettivamente liberi, l’ultimo contiene l’indirizzo ai successivi n blocchi liberi. L’importanza è data dalla possibilista di trovare rapidamente gli indirizzi di un gran numero di blocchi liberi.   

|||||CONTEGGIO
Generalmente più blocchi contigui si possono allocare o liberare contemporaneamente, soprattutto quando lo spazio viene allocato usando l’algoritmo di allocazione. Anziché tener una lista di n indirizzi liberi, è sufficiente tenere l’indirizzo del primo e il numero di blocchi liberi. 

6. EFFICIENZA E PRESTAZIONI 
I dischi tendono di solito a essere il principale collo di bottiglia per le prestazioni in una sistema  

|||||EFFICIENZA 
L’uso efficiente di un disco dipende fortemente dagli algoritmi usati per l’allocazione del disco e la gestione delle dir. Si devono tenere in considerazione anche il tipo di dati normalmente contenuti in un elemento. Di solito si memorizza la data dell’ultima scrittura, altri dell’ultimo accesso aggiornando ogni volta un campo della dir. Questa modifica richiede la lettura nella memoria del blocco, la modifica e la riscrittura.  Una delle difficoltà nella scelta della dimensione dei puntatori o di qualsiasi altra dimensione di allocazione fissa all’interno di un SO è la pianificazione degli effetti provocati dal cambiamento della tecnologia. Con la crescita della capacita dei dischi, i dischi più grandi si dovevano suddividere in partizioni di 32 MB fino a quando non è stato modificato il file system. Il modo della gestione delle strutture e l’allocazione dinamica. Naturalmente gli algoritmo che manipolano queste tabelle sono ora più complessi e il SO è un può più lento dovendo allocare e rilasciare dinamicamente gli elementi.   

|||||PRESTAZIONI
Dopo aver scelto gli algoritmi fondamentali del file system le prestazioni possono essere migliorate in diversi modi. Alcuni controllori di unita a disco contengono una quantica di memoria locale sufficiente grande da memorizzare un’intera traccia del disco alla volta. Si legge la traccia e il controllore trasferisce quindi al SO tutte le richieste di settore. Quando i blocchi sono trasferiti dal controllore del disco alla memoria centrale, il sistema operativo ha la possibilità di inserirli in una propria cache nella memoria centrale. Alcuni sistemi riservano una sezione separata della memoria centrale come cache del disco, altri impiegano una cache delle pagine per i file. Questo metodo è noto come memoria virtuale unificata. Alcune versioni di linux e unix prevedono la cosiddetta buffer cache unificata. Serve per risolvere i problemi derivati dalla double caching ossia nell’accesso ad un file sia tramite la mappatura dei file sia tramite l’ordinaria chiamata di sistema. Con una buffer cache unificata sia l’associazione alla memoria che le chiamate di sistema usano la stessa cache.  
In generale l’algoritmo LRU è ragionevole per sostituire blocchi e le pagine. Le scritture sincrone avvengono nell’ordine in cui le riceve il sottosistema per la gestione del disco. Nella maggior parte dei casi si usano scritture asincrone. Nelle scritture asincrone si memorizzano i dati nella cache e si restituisce immediatamente il controllo alla procedura. gli accessi frequenti si potrebbero invece ottimizzare con tecniche note come rilascio indietro e lettura anticipato. Il rilascio indietro rimuove una pagina dalla memoria di transito non appena si verifica una lettura di pagina successiva; le pagine precedenti non saranno usate. La lettura anticipata invece si leggono e si mettono nella cache la pagina richiesta e parecchie successive poiché si pensi che serviranno presto.  La cache delle pagine, il file system e i driver del disco interagisco in modi interessanti. Quando i dati vengono scritti su un file del disco, le pagine sono memorizzate nella cache che qui funge da buffer mentre il driver del disco ordina la propria coda di dati in uscita in base all’indirizzo sul disco. Per grandi quantità di dati la scrittura è più veloce della lettura se avviene tramite file system.

7. RIPRISTINO 
Poiché i file e le dir sono mantenuti sia in memoria centrale sia nei dischi, è necessario aver cura di assicurare che il verificarsi di un malfunzionamenti nel sistema non comporti la perdita di dati.  

|||||VERIFICA DELLA COERENZA 
Una parte delle informazioni contenute nella dir è mantenuta in memoria centrale o in cache allo scopo di accelerarne gli accessi. Queste informazioni sono generalmente più aggiornate delle corrispondenti informazioni presenti in memoria secondaria piche la scrittura nei dischi dei dati contenuti nella cache non si verifica necessariamente nell’istante in cui occorrono le modifiche. Si consideri il crollo del sistema, il contenuto della cache e del buffer sono persi. Questo evento può lasciare il file system in uno stato di incoerenza. Il verificatore della coerenza è un programma di sistema che confronta i dati delle dir con quelli contenuti nei blocchi dei dischi tendono di correggere ogni incoerenza. Unix usa la cache per la lettura mentre la scrittura avviene in modo sincrono.   

|||||COPIE DI RISERVA
Poichè possono verificarsi malfunzionamenti e perdite dei dati anche nei dischi magnetici, c’è bisogno che i dati presenti nei dischi vengono salvati altrove in modo che un eventuale perdita posso essere rapidamente risolta. Ciò avviene tramite le cosiddette  copie di riserva o comunemente conosciute come backup  

8. FILE SYSTEM CON REGISTRAZIONE DELLE MODIFICHE 
Spesso si adottano algoritmi e tecnologie anche nel caso in cui sono stati progettati per altre situazioni. È il caso degli algoritmi per il ripristino sviluppati nell’area dei sistemi di gestione delle basi dati. Questi algoritmi sono stati applicati con successo al problema della verifica della coerenza. Si ricordi che le strutture dati del file system che risiedono nei dischi, come le strutture delle dir, i puntatori a blocchi possono diventerà incoerenti nel caso di un crollo del sistema. Il metodo che consente l’incoerenza delle strutture per poi correggere gli errori in una fase di ripristino presenta diversi problemi tra questi è che l’incoerenza potrebbe essere irrisolvibile. La soluzione a questo problema consiste nell’applicare agli aggiornamenti dei metadati relativi al file system metodi di ripristino basati sulla registrazione delle modifiche. Fondamentalmente tutte le modifiche vengono annotate in un file log. Ogni insieme di operazioni che esegue uno specifico compito si chiama transazione e non appena le modifiche sono riportate nel file di registrazione, le operazioni si considerano portate a termine. Se si verifica un crollo del sistema si verifica il contenuto del log. Le transazioni presenti non sono mai state ultimate nel file system anche se il SO le definisce portate a termine.    