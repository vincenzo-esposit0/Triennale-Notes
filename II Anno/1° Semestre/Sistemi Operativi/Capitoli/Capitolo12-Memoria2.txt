CAPITOLO 12:  MEMORIA SECONDARIA E TERZIARIA 
 
1. STRUTTURA DEI DISPOSITIVI DI MEMORIZZAZIONE 
Dischi magnetici I dischi magnetici sono il mezzo fondamentale di memoria secondaria dei moderni sistemi di calcolo. Concettualmente i dischi sono relativamente semplice: i piatti hanno una forma piana e una superficie di material magnetico dove le informazione vengono registrate magneticamente. Le testine di lettura e scrittura sono sospesa su ciascuna superficie d’ogni piatto e sono attaccate al braccio del disco che le muove in blocco. La superficie di un piatto è divisa logicamente  in tracce circolari a loro volta suddivise in settore. L’insieme delle tracce corrispondenti a un braccio formano un cilindro. In un’unita a disco possono esservi migliaia di cilindri. Quando un disco è in funzione un motore lo fa ruotare ad alta velocità. L’efficienza è caratterizzato dal tempo di trasferimento, il tempo di posizionamento e il tempo di ricerca. Poiché le testine di un disco sono sospese su un cuscino d’aria sottilissimo, esiste il pericolo che la testina urti la superficie in tal caso si parla di crollo della testina e causa la rottura irreversibile del disco. Un disco può essere rimovibile ciò permette che diversi dischi siano montanti secondo le necessita. I dischetti sono dischi magnetici dell’rodine di 1.44 MB dove la tesina viene poggiata sul disco per leggere e scrivere e per questo ruota più lentamente. I dischi possono essere collegati attraverso de fili detti bus e possono essere EIDE, SATA, PATA, SCSI, USB. Il trasferimento dei dati in un bus è eseguito da speciali unita di elaborazione dette controllori. Gli adattatori o controllori di macchina sono i controllori posti all’estremità relativa al calcolatore del bus.   Nastri magnetici I nastri magnetici sono stati i primi supporti di memorizzazione secondaria. Pur avendo una veloce trasferimento, il tempo di posizionamento è troppo elevato. Gli usi principali adesso sono quelli della creazione di backup.  

2. STRUTTURA DEI DISCHI 
I moderni dischi sono considerati come grandi array monodimensionale di blocchi logici, dove un blocco logico è la minima unita di trasferimento. La dimensione di un blocco logico è di solito di 512 byte sebbene alcuni dischi si possono formattare a basso livello allo scopo di ottener una diversa dimensione dei blocchi logici. L’array monodimensionale di blocchi logici corrisponde in modo sequenziale ai settori del disco. Sfruttando questa corrispondenza almeno in teoria sarebbe possibile trasformare gli indirizzi logici in indirizzi fisici costituiti da numero di cilindro, traccia, settore. In pratica vi sono 2 motivi che rendono difficile quest’operazione in primo luogo la maggior parte dei dischi contiene settori difettosi, in secondo luogo il numero di settori per traccia in certe unita a disco no è costante. Nei supporti che impiegano velocità lineare costante la densità di bit per traccia è uniforme. Più è lontana dal centro del disco, tanto maggiore è la lunghezza della traccia. L’unita aumenta la sua velocità di rotazione man mano che le testine vanno verso l’esterno (cd e dvd). Mente quando la rotazione rimane la stessa la densità di bit decresce dalla tracce interne alle tracce più esterne e mantener e costante il flusso dei dati. Questo metodo è detto velocità angolare costante. 

3. CONNESSIONE DEI DISCHI 
I calcolatori accedono alla memoria secondaria in due modi: nei sistemi di piccole dimensioni il modo più comune è tramite le porte di IO, oppure in modo remoto per mezzo di un file system distribuito.   

|||||MEMORIA SECONDARIA CONNESSA ALLA MACCHINA 
Alla memoria secondaria connessa alla macchina si accede tramite le porte locali di IO. I comuni pc usano IDE o ATA. Le stazioni di lavoro a fibra ottica e SCSI. L’architettura SCSI è un’architettura a bus il cui supporto fisico è di solito un cavo piato con un gran numero di conduttori. Consente di avere sul bus fino a 16 dischi. L’FC è un’architettura seriale ad alta velocità che può funzionare sia su fibra che su cavo e ci si aspetta grande potenzialità da questa connessione.   
|||||MEMORIA SECONDARIA CONNESSA ALLA RETE
Un dispositivo di memoria secondaria connessa alla rete è un sistema di memoria special al quale si accede in modo remoto per mezzo di una rete id trasmissione di dati. I client accedono alla memoria connessa alla rete tramite un’interfaccia RPC come NFS per unix o CIFS per win.  La memoria secondaria connessa alla rete fornisce un modo semplice per condividere spazio di memorizzazione a tutti i calcolatori di una lan con la stessa facilita di gestione dei nome  degli accessi caratteristica della memoria secondaria locale. Tuttavia un sistema del genere ha prestazioni inferiori rispetto a memorie secondarie locali.  

4. SCHEDULING DEL DISCO 
Una delle responsabilità del sistema operativo è quella di fare un uso efficiente delle risorse fisiche, nel caso delle unita a disco far fronte a questa responsabilità significa garantire tempo d’accesso contenuti e ampiezze di banda elevate. Il tempo d’accesso si può scindere in due componenti: tempo di ricerca cioè il tempo necessario finche il braccio dell’unita a disco sposti  Le testine fino al cilindro, latenza di rotazione cioè il tempo aggiuntivo necessario perché il disco ruoti finche il settore desiderato si trovi sotto la testina.  
Ogni volta che devono compiere operazioni di IO con un’unita a disco, un processo impartisce al sistema operativo una chiamata di sistema. La richiesta contiene diverse informazioni: 
? Se l’operazione sia di immissione o emissione dati 
? L’indirizzo del disco ? L’indirizzo di memoria al quale eseguire il trasferimento 
? Il numero di byte da trasferire.  
Se l’unita a disco desiderata e il controllore sono disponibili, la richiesta si può immediatamente soddisfare; altrimenti le nuove richiese si aggiungono alla coda di richieste inevase relativa a quell’unita. La coda relativa a un’unita a disco in un sistema con multiprogrammazione può spesso essere piuttosto lunga, sicché il SO sceglie quale fra le richieste inevase conviene scrivere prima.

|||||SCHEDULING FCFS
La forma più semplice è quello di esaudire le richieste in base all’ordine di arrivo. 
 
|||||SCHEDULING SSTF
Sembra ragionevole servire le richieste più vicine alla posizione corrente prima di spostarla in un’area più lontana. Riscegli la richiesta che da minimo tempo di spostamento. Riduce di un terzo il percorso del FCFS ma nonostante ciò ha dei svantaggi che è quello della starvation e poi non è ottimale.  
 
|||||SCHEDULING S-SCAN S
econdo l’algoritmo S-SCAN il braccio dell’unita a disco parte da un estremo del disco e si sposta verso l’atra estremità risolvendo le richieste che incontra durante il percorso. Se una nuova richiesta arriva e la testina ha superato da poco tale posizione, essa deve attendere che la testina arriva all’altra estremità e inverte la sua marcia. è conosciuto anche come algoritmo dell’ascensore. Si noti che poche sono le richieste immediatamente vicine durante il cambio di marcia. 
 
|||||SCHEDULING C-SCAN 
L’algoritmo C-SCAN è una variante dell’S-SCAN e la variazione è che non inverte il senso di marcia bensi inizia dall’inizio del disco stesso vedendo il disco come una lista circolare 
 
|||||SCHEDULING LOCK E C-LOCK
Secondo la descrizione appena fatta, sia l’algoritmo SCAN che C-SCAN spostano il braccio dell’unita attraverso tutta l’ampiezza del disco; all’atto pratico nessuno dei sue algoritmi è codificato in questo modo: più comunemente il braccio si sposta solo finche ci sono altre  richieste da servire in quella direzione dopo di che cambia immediatamente direzione senza giungere all’stremo del disco.  

|||||SCELTA DI UN ALGORITMO DI SCHEDULING 
Giacche esistono tanti diversi algoritmi bisogna individuare quale sia il migliore. Per qualunque algoritmo di scheduling, le prestazioni dipendono comunque in larga misura dal numero e dal tipo di richiesta. Anche la posizione delle dir e dei blocchi indici è importante piche ogni file deve essere aperto per essere usato e visto che l’apertura di un file richiede una ricerca attraverso la struttura della dir, vi saranno frequenti accessi alla directory. A causa dei diversi problemi lo scheduling del disco dovrebbe costituire un modulo a se stante del SO cosi come da poter essere sostituto da un altro algoritmo qualora ciò non fosse necessario. I produttori di unita a disco hanno collaborato alla limitazione di questi problemi incorporando tali algoritmi all’interno dei controllori contenuti nelle unita a disco facendo si che in automatico vengono scelti gli algoritmi più appropriati.  

5. GESTIONE DELL’UNITA’ A DISCO 

|||||FORMATTAZIONE DEL DISCO
Un disco magnetico nuovo è tabula rasa: un insieme di uno o più piatti privi di file system. Per prima cosa deve essere diviso in settori e questa fase è detta formattazione fisica o di basso livello. Si riempio il disco di una struttura dati per ogni settore consistente di una intestazione e una coda. L’intestazione e la coda contengono informazioni usate dal controllo re del disco ad esempio il numero del settore e un codice per la correzione degli errori EEC. Quando si effettua un’ordinaria operazione si aggiorna il valore EEC secondo il contenuto dell’area e i dati del settore. Se risulta una discrepanza tra EEC e i dati letti nel settore significa che il settore potrebbe essere difettoso. La formattazione fisica è effettuata in larga parte da i costruttori in modo che testino anche il disco e controllino in numero dei settori danneggiati. Per usare il disco il SO deve creare uno o più partizioni e in ognuna creare un file system.   

|||||BLOCCO D'AVVIAMENTO
affinché un calcolatore possa entrare in funzione ad esempio quando viene accesa o riavviata è necessario che esegua un programma iniziale; i solito questo programma d’avviamento iniziale è piuttosto semplice. Esso inizializza in SO in tutti i suoi aspetti, dai registri della CPU all’avvio del SO. Per  far ciò il programma d’avviamento trova il kernel del SO lo carica nella memoria e salta a un indirizzo iniziale per avviar l’esecuzione del SO. Per la maggior parte dei calcolatori il blocco d’avviamento viene memorizzato nella ROM. Poiché la ROM non è aggiornabile, nella ROM viene memorizzato un caricatore d’avviamento il quale va a leggere all’inizio della partizione che contiene il SO e quest’ultimo permette l’avvio. Questo sistema colloca nel primo settore del disco chiamato MBR il codice di avviamento e una tabella che indica le varie partizioni e un flag che indica in quale partizione è presente il SO.   

|||||BLOCCHI DIFETTOSI
Le unita a disco sono strutturalmente portate ai malfunzionamenti perché sono costituiti da parti mobile a bassa tolleranza. A volte può verificarsi un guasto irreparabile e l’unita a disco deve essere sostituita. Più frequentemente invece uno o più settori diventa difettoso. Essi sono trattati a differenza del disco e secondo il controllore.  
Nel DOS bisognava chiamare una funzione del SO che permetteva di correggere o prendere soluzioni nel caso in cui uno di questi settori diventasse malfunzionante. Unita a disco più sofisticate come dischi SCI hanno strategie di recupero dei blocchi difettosi. Il controllore tiene una lista dei blocchi malfunzionante dell’unita a disco che è inizializzata durante la formattazione fisica da parte del produttore e aggiornata man mano che si verificano nuovi malfunzionamenti. La formattazione mette anche a disposizione dei settori di riserva non visibili al SO nel caso in cui uno diventi difettoso viene rimpiazzato da uno di questi settori. La maggior parte di questi dischi mette a disposizione interi cilindri per questa operazione. 

6. GESTIONE DELL’AREA D’AVVICENDAMENTO L’avvicendamento è stato introdotto dove abbiamo trattato lo spostamento di interi processi tra disco e memoria centrale. In quel contesto l’avvicendamento interviene quando l’ammontare della memoria fisica si abbassa fino al punto di raggiungere la sogli critica e  i processi passano dalla memoria all’area di avvicendamento per liberare memoria. Nella pratica pochissimi SO realizzano l’avvicendamento nel modo descritto: essi infatti, combinano l’avvicendamento con tecniche di memoria virtuale per coinvolgere nell’operazione solo alcune pagine e on necessariamente interi processi. Tant’è che alcuni sistemi considerano avvicendamento e paginazione termini intercambiabile.  La gestione dell’area d’avvicendamento è un altro compito di basso libello del sistema operativo la memoria virtuale usa lo spazio dei dischi come esenzione della membra centrale: poiché l’accesso alle unita a disco è molto più lento dell’accesso alla memoria centrale, l’uso di un’area d’avvicendamento riduce notevolmente le prestazioni del stima. L’obiettivo principale nella progettazione e realizzazione di un’area di avvicendamento è di fornire la migliore produttività per il system della memoria virtuale.   

|||||USO DELL'AREA D'AVVICENDAMENTO
L’area d’avvicendamento è usata in modi diversi da sistemi operativi diversi in funzione degli algoritmi di gestione della memoria applicati. I sistemi che adottano l’avvicendamento dei processi nella moria possono usare l’area di avvicendamento per mantener l’intera immagine del processo inclusi si segmenti dei dati e del codice; i sistemi a paginazione invece possono semplicemente memorizzarvi pagine non contenute nella memoria centrale. Lo spazio richiesto dall’area d’avvicendamento per un sistema può quindi variare secondo la quanto di memoria fisica la memoria virtuale.  Un sistema che esaurisca l’area d’avvicendamento potrebbe essere costretto a terminare forzatamente i processi o ad arrestarsi completamente.   

|||||COLLOCAZIONE DELL'AREA D'AVVICENDAMENTO
Le possibili collocazioni per un’area d’avvicendamento sono due: all’interno del normale file system o in una partizione del disco a se stante. Se l’area d’avvicendamento è semplicemente un grande file all’interno de file system, si possono usare le ordinarie funzioni dei file system pere crearla, assegnargli un nome e allocare spazio per essa. Questo criterio sebbene sia semplice da realizzare è inefficiente: l’attraversamento della struttura delle dir  e l’uso delle strutture dati per l’allocazione dello spazio nei dischi richiede tempo. Le prestazioni si possono migliorare impiegando la memoria fisica come cache per le informazioni relative alla posizione dei blocchi e anche usando strutture speciali per l’allocazione in blocchi fisicamente contigui del file d’avvicendamento, ma il costo dovuto all’attraversamento del file system  e delle sue strutture dati permane. In alternativa all’area di avvicendamento si può creare un’apposta partizione del disco non formattata e si velocizza  perché no si deve attraversare il file system. Si crea frammentazione interna ma dato che questa area ha vita breve, è un prezzo che si può pagare. 

7. STRUTTURE RAID 
L’evoluzione tecnologica ha reso le unita a disco progressivamente più piccole e meno costose. Oggi è possibile equipaggiare sistemi con più dischi senza spendere somme esorbitanti. Attraverso la configurazione raid è possibile da un lato velocizzare l’accesso e da un altro effettua copie di dischi qualora uno potrebbe rompersi. 

|||||MIGLIORAMENTO DELL'AFFIDABILITà TRAMITE LA RID
La possibilità che un disco si rompa si guasti è molto alta molto più alta della possibilità che uno specifico disco isolato presenti un guasto. La soluzione dell’affidabilità sta nell’introdurre una ridondanza e quindi in caso di guasto basta sostituire il disco. Il metodo più semplice è quello del mirroring ogni disco logico consiste di due fisici e ogni scrittura si effettua in entrambi id dischi. Ciò è sufficiente a risolvere i problemi dipesi da un guasto relativo alla rottura di un disco no pero nel caso di un disastro naturale.  Nel caso in cui si hanno interruzioni di corrente e una scrittura no n andasse a buon fine, si deve avere il modo per non far corrompere il file system. una soluzione prevede la scrittura in uno solo dei dischi e solo successivamente nell’altro in modo da avere nella copia sempre scritture portate a termine.   

|||||MIGLIORAMENTO TRAMITE IL PARALLELISMO
L’access in parallelo di più dischi può portare grossi vantaggi. Con la copiatura speculare dei dischi la frequenza con la quale si possono gestire le richieste di lettura raddoppia poiché ciascuna richiesta si può inviare indifferentemente a uno dei due dischi. Per migliorare la capacita di trasferimento i dati vengono distribuiti in sezione su più dischi. Questa forma nota come sezionamento dei dati, consiste nel distribuire i bit di ciascun byte su pi dischi facendo si che la quantità di dati letti o scritti sai 8 volte superiore. Questo pero porta ad un grave svantaggio, nel caso in cui uno dei dischi si rompa, tutti i dati sono irrecuperabile. 

|||||Livelli RAID 
La tecnica copiatura speculare offre un’alta affidabilità ma è costosa, la tecnica del sezionamento offre un’alta capacita di trasferimento ma non migliora l’affidabilità.  
?- Raid 0. il livello 0 si riferisce a batteria dei dischi on sezionamento a livello di blocchi ma senza ridondanza ? Raid 1. il livello 1 si riferisce alla copiatura speculare 
?- Raid 2. noto anche come organizzazione dei codice per la correzione degli errori ECC. da molto tempo i dischi usano tecniche di riconoscimento degli errori. In un sistema di questo tipo ogni byte di memoria ha associato un bit di parità che indica con valore 1 sono in numero pari o dispari.  
?- Raid 3. con il livello 3 o organizzazione con bit di parità intercalati, si migliora il raid 2 usando un unico bit di parità per individuare gli errori. Se uno dei settori è danneggiato si conosce esattamente di quale settore si tratta e calcolando la parità si conosce il suo valore. È migliore rispetto al 2 quindi il 2 non viene proprio usato. È migliore dell’1 per 2 motivi: 1 perchè si usa un solo disco per la parità anziché uno per ogni disco, 2 e che essendo la lettura e scrittura su byte distribuiti la velocità aumenta di n volte.  
?- Raid 4. noto come organizzazione con blocchi di parità intercalati, s’impiega il sezionamento a livello dei blocchi come nel raid 0 e inoltre si tiene un blocco di parità in un disco separato. Se un dei dischi si guasta, il blocco di parità serve per recuperare il contenuto.  
?- Raid 5. noto come organizzazione con blocchi intercalati a parità distribuita, differisce dal 4 per il fatto che invece di memorizzare i dati in n dischi e la parità in un disco separati, i dati e le informazioni di parità sono distribuite tra gli n+1 dischi. Ogni blocco memorizza la parità e gli altri i dati. È il più comune sistema raid. 
?- Raid 6. l livello 6 noto anche come schema di ridondanza P+Q è molto esimie al5 5 ma memorizza ulteriori informazioni ridondanti per potere gestire guasti contemporanei di più dischi. Invece della parità si usano codici di read solomon. ?- Raid 0+1. il livello 0+1 consiste in una combinazione del raid 0 e raid 1. il livello 1 fornisce le prestazioni mentre l’1 l’affidabilità. Se si guasta un singolo disco, ‘intera sezione di dati diventa inaccessibile, lasciando disponibile solo l’altra sezione 
?- Raid 1+0. si fa prima la copiatura e poi si sezionano i dati. Con un guasto nel raid 1+0 il singolo disco diventa inaccessibile ma il suo duplicato è ancora disponibile, come tutti gli altri dischi.  
Il raid può essere implementato sia a livello software che hardware. Un’altra caratteristica del raid è la previsione di dischi di scorta che possono sostituire immediatamente dischi rotti.  
 
8. STRUTTURE PER LA MEMORIZZAZIONE TERZIARIA 

|||||Dispositivi per la memorizzazione terziaria 
La memoria terziaria consiste di mezzi rimovibili di cui dischetti, cd rom e dvd I dischi rimuovili sono costituiti da dischi ottici cd e dvd che possono essere riscrivibile oppure a sola lettura. La scrittura avviene attraverso un laser che magnetizza un settore.   
Nastri: Costituite da una bobina che gira intorno a ma il tempo di riavvolgimento è troppo lento.   
       